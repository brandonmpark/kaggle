{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15674932</td>\n",
       "      <td>Okwudilichukwu</td>\n",
       "      <td>668</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181449.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15749177</td>\n",
       "      <td>Okwudiliolisa</td>\n",
       "      <td>627</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49503.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15694510</td>\n",
       "      <td>Hsueh</td>\n",
       "      <td>678</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184866.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15741417</td>\n",
       "      <td>Kao</td>\n",
       "      <td>581</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2</td>\n",
       "      <td>148882.54</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84560.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15766172</td>\n",
       "      <td>Chiemenam</td>\n",
       "      <td>716</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15068.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CustomerId         Surname  CreditScore Geography Gender   Age  Tenure  \\\n",
       "id                                                                           \n",
       "0     15674932  Okwudilichukwu          668    France   Male  33.0       3   \n",
       "1     15749177   Okwudiliolisa          627    France   Male  33.0       1   \n",
       "2     15694510           Hsueh          678    France   Male  40.0      10   \n",
       "3     15741417             Kao          581    France   Male  34.0       2   \n",
       "4     15766172       Chiemenam          716     Spain   Male  33.0       5   \n",
       "\n",
       "      Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "id                                                                        \n",
       "0        0.00              2        1.0             0.0        181449.97  \n",
       "1        0.00              2        1.0             1.0         49503.50  \n",
       "2        0.00              2        1.0             0.0        184866.69  \n",
       "3   148882.54              1        1.0             1.0         84560.88  \n",
       "4        0.00              2        1.0             1.0         15068.83  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/train.csv', index_col='id')\n",
    "data.head()\n",
    "\n",
    "X = data.drop('Exited', axis=1)\n",
    "y = data['Exited']\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add features\n",
    "\n",
    "X['BalanceSalaryRatio'] = X['Balance'] / X['EstimatedSalary'] \n",
    "X['TenureByAge'] = X['Tenure'] / X['Age']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X.drop(['CustomerId', 'Surname'], axis=1, inplace=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('one_hot', OneHotEncoder())\n",
    "])\n",
    "\n",
    "num_attribs = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary', 'BalanceSalaryRatio', 'TenureByAge']\n",
    "cat_attribs = ['Geography', 'Gender', 'HasCrCard', 'IsActiveMember']\n",
    "\n",
    "preprocessing_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_attribs),\n",
    "    ('cat', cat_pipeline, cat_attribs)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessing_pipeline.fit_transform(X_train)\n",
    "X_val = preprocessing_pipeline.transform(X_val)\n",
    "X_test = preprocessing_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Various Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 52, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 8, 'max_depth': 9}\n",
      "0.8644202811736708\n",
      "0.8647880041365047\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = {'n_estimators': np.arange(30, 76), 'max_features': np.arange(1, 11), 'max_depth': np.arange(1, 11), 'min_samples_split': np.arange(2, 11), 'min_samples_leaf': np.arange(1, 11)}\n",
    "\n",
    "\n",
    "forest_search = RandomizedSearchCV(RandomForestClassifier(), param_grid, cv=5,\n",
    "                           scoring='accuracy', return_train_score=True, n_jobs=-1, n_iter=50)\n",
    "forest_search.fit(X_train, y_train)\n",
    "print(forest_search.best_params_)\n",
    "print(forest_search.best_score_)\n",
    "y_pred = forest_search.predict(X_val)\n",
    "print(accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(**forest_search.best_params_)\n",
    "forest.fit(X_train, y_train)\n",
    "# view the feature scores\n",
    "feature_scores = pd.Series(forest.feature_importances_).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 55, 'learning_rate': 0.2, 'estimator__min_samples_split': 5, 'estimator__min_samples_leaf': 3, 'estimator__max_features': 8, 'estimator': DecisionTreeClassifier(max_depth=3)}\n",
      "0.864215603640158\n",
      "0.8616533092037229\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "param_grid = {'n_estimators': np.arange(30, 76), 'learning_rate': np.arange(0.1, 1.1, 0.1), 'estimator__min_samples_split': np.arange(2, 11), 'estimator__min_samples_leaf': np.arange(1, 11), 'estimator__max_features': np.arange(1, 11), 'estimator': [DecisionTreeClassifier(max_depth=1), DecisionTreeClassifier(max_depth=2), DecisionTreeClassifier(max_depth=3)]}\n",
    "\n",
    "ada_search = RandomizedSearchCV(AdaBoostClassifier(), param_grid, cv=5,\n",
    "                            scoring='accuracy', return_train_score=True, n_jobs=-1, n_iter=50)\n",
    "ada_search.fit(X_train, y_train)\n",
    "print(ada_search.best_params_)\n",
    "print(ada_search.best_score_)\n",
    "y_pred = ada_search.predict(X_val)\n",
    "print(accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 32, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 10, 'max_depth': 7, 'learning_rate': 0.1}\n",
      "0.8642976991794903\n",
      "0.8646910548086867\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "param_grid = {'n_estimators': np.arange(30, 76), 'learning_rate': np.arange(0.1, 1.1, 0.1), 'min_samples_split': np.arange(2, 11), 'min_samples_leaf': np.arange(1, 11), 'max_features': np.arange(1, 11), 'max_depth': np.arange(1, 11)}\n",
    "\n",
    "gb_search = RandomizedSearchCV(GradientBoostingClassifier(), param_grid, cv=5, scoring='accuracy', return_train_score=True, n_jobs=-1, n_iter=50)\n",
    "gb_search.fit(X_train, y_train)\n",
    "print(gb_search.best_params_)\n",
    "print(gb_search.best_score_)\n",
    "y_pred = gb_search.predict(X_val)\n",
    "print(accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weights': 'distance', 'p': 2, 'n_neighbors': 20, 'leaf_size': 20}\n",
      "0.8575757786434386\n",
      "0.8569674250258531\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': np.arange(10, 30),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2],\n",
    "    'leaf_size': np.arange(1, 51)\n",
    "}\n",
    "\n",
    "knn_search = RandomizedSearchCV(KNeighborsClassifier(), param_grid, cv=5,\n",
    "                            scoring='accuracy', return_train_score=True, n_jobs=-1, n_iter=20)\n",
    "knn_search.fit(X_train, y_train)\n",
    "print(knn_search.best_params_)\n",
    "print(knn_search.best_score_)\n",
    "y_pred = knn_search.predict(X_val)\n",
    "print(accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandonmpark/Desktop/Coding/kaggle/.conda/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'rbf', 'gamma': 'scale', 'degree': 2, 'C': 1.0}\n",
      "0.8625597557811913\n",
      "0.8608130816959669\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(C=1, degree=2, gamma='scale', kernel='rbf', probability=True)\n",
    "svc.fit(X_train, y_train)\n",
    "print(svc.score(X_train, y_train))\n",
    "y_pred = svc.predict(X_val)\n",
    "print(accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 33, 'min_samples_split': 8, 'min_samples_leaf': 6, 'max_features': 10, 'max_depth': 9}\n",
      "0.862430474331805\n",
      "0.8626228024819028\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "param_grid = {'n_estimators': np.arange(30, 76), 'max_features': np.arange(1, 11), 'max_depth': np.arange(1, 11), 'min_samples_split': np.arange(2, 11), 'min_samples_leaf': np.arange(1, 11)}\n",
    "\n",
    "extra_search = RandomizedSearchCV(ExtraTreesClassifier(), param_grid, cv=5,\n",
    "                            scoring='accuracy', return_train_score=True, n_jobs=-1, n_iter=50)\n",
    "extra_search.fit(X_train, y_train)\n",
    "print(extra_search.best_params_)\n",
    "print(extra_search.best_score_)\n",
    "y_pred = extra_search.predict(X_val)\n",
    "print(accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8903666891688091\n",
      "0.8416817476732161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandonmpark/Desktop/Coding/kaggle/.conda/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 100), activation='relu', solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "mlp.fit(X_train, y_train)\n",
    "print(mlp.score(X_train, y_train))\n",
    "y_pred = mlp.predict(X_val)\n",
    "print(accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandonmpark/Desktop/Coding/kaggle/.conda/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/brandonmpark/Desktop/Coding/kaggle/.conda/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/brandonmpark/Desktop/Coding/kaggle/.conda/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END final_estimator__C=0.6, final_estimator__penalty=l2, final_estimator__solver=saga, stack_method=predict_proba; total time= 1.5min\n",
      "[CV] END final_estimator__C=0.6, final_estimator__penalty=l2, final_estimator__solver=saga, stack_method=predict_proba; total time= 1.6min\n",
      "[CV] END final_estimator__C=0.6, final_estimator__penalty=l2, final_estimator__solver=saga, stack_method=predict_proba; total time= 1.6min\n",
      "[CV] END final_estimator__C=0.6, final_estimator__penalty=l2, final_estimator__solver=saga, stack_method=predict_proba; total time= 1.6min\n",
      "[CV] END final_estimator__C=0.6, final_estimator__penalty=l2, final_estimator__solver=saga, stack_method=predict_proba; total time= 1.6min\n",
      "[CV] END final_estimator__C=0.6, final_estimator__penalty=l1, final_estimator__solver=liblinear, stack_method=predict_proba; total time= 1.6min\n",
      "[CV] END final_estimator__C=0.6, final_estimator__penalty=l1, final_estimator__solver=liblinear, stack_method=predict_proba; total time= 1.7min\n",
      "[CV] END final_estimator__C=0.6, final_estimator__penalty=l1, final_estimator__solver=liblinear, stack_method=predict_proba; total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandonmpark/Desktop/Coding/kaggle/.conda/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/brandonmpark/Desktop/Coding/kaggle/.conda/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END final_estimator__C=0.8, final_estimator__penalty=l2, final_estimator__solver=liblinear, stack_method=auto; total time= 1.5min\n",
      "[CV] END final_estimator__C=0.8, final_estimator__penalty=l2, final_estimator__solver=liblinear, stack_method=auto; total time= 1.6min\n",
      "[CV] END final_estimator__C=0.8, final_estimator__penalty=l2, final_estimator__solver=liblinear, stack_method=auto; total time= 1.6min\n",
      "[CV] END final_estimator__C=0.8, final_estimator__penalty=l2, final_estimator__solver=liblinear, stack_method=auto; total time= 1.6min\n",
      "[CV] END final_estimator__C=0.6, final_estimator__penalty=l1, final_estimator__solver=liblinear, stack_method=predict_proba; total time= 1.7min\n",
      "[CV] END final_estimator__C=0.8, final_estimator__penalty=l2, final_estimator__solver=liblinear, stack_method=auto; total time= 1.6min\n",
      "[CV] END final_estimator__C=0.6, final_estimator__penalty=l1, final_estimator__solver=liblinear, stack_method=predict_proba; total time= 1.7min\n",
      "[CV] END final_estimator__C=0.4, final_estimator__penalty=l1, final_estimator__solver=saga, stack_method=predict_proba; total time= 1.6min\n",
      "[CV] END final_estimator__C=0.4, final_estimator__penalty=l1, final_estimator__solver=saga, stack_method=predict_proba; total time= 1.5min\n",
      "[CV] END final_estimator__C=0.4, final_estimator__penalty=l1, final_estimator__solver=saga, stack_method=predict_proba; total time= 1.6min\n",
      "[CV] END final_estimator__C=0.4, final_estimator__penalty=l1, final_estimator__solver=saga, stack_method=predict_proba; total time= 1.6min\n",
      "[CV] END final_estimator__C=0.4, final_estimator__penalty=l1, final_estimator__solver=saga, stack_method=predict_proba; total time= 1.6min\n",
      "[CV] END final_estimator__C=0.1, final_estimator__penalty=l2, final_estimator__solver=saga, stack_method=predict_proba; total time= 1.5min\n",
      "[CV] END final_estimator__C=0.1, final_estimator__penalty=l2, final_estimator__solver=saga, stack_method=predict_proba; total time= 1.6min\n",
      "[CV] END final_estimator__C=0.1, final_estimator__penalty=l2, final_estimator__solver=saga, stack_method=predict_proba; total time= 1.5min\n",
      "[CV] END final_estimator__C=0.1, final_estimator__penalty=l2, final_estimator__solver=saga, stack_method=predict_proba; total time= 1.5min\n",
      "[CV] END final_estimator__C=0.1, final_estimator__penalty=l2, final_estimator__solver=saga, stack_method=predict_proba; total time= 1.5min\n",
      "[CV] END final_estimator__C=0.1, final_estimator__penalty=l2, final_estimator__solver=liblinear, stack_method=auto; total time= 1.6min\n",
      "[CV] END final_estimator__C=0.1, final_estimator__penalty=l2, final_estimator__solver=liblinear, stack_method=auto; total time= 1.6min\n",
      "[CV] END final_estimator__C=0.1, final_estimator__penalty=l2, final_estimator__solver=liblinear, stack_method=auto; total time= 1.6min\n",
      "[CV] END final_estimator__C=0.1, final_estimator__penalty=l2, final_estimator__solver=liblinear, stack_method=auto; total time= 1.6min\n",
      "[CV] END final_estimator__C=0.1, final_estimator__penalty=l2, final_estimator__solver=liblinear, stack_method=auto; total time= 1.6min\n",
      "[CV] END final_estimator__C=0.2, final_estimator__penalty=l2, final_estimator__solver=saga, stack_method=predict_proba; total time= 1.5min\n",
      "[CV] END final_estimator__C=0.2, final_estimator__penalty=l2, final_estimator__solver=saga, stack_method=predict_proba; total time= 1.6min\n",
      "[CV] END final_estimator__C=0.2, final_estimator__penalty=l2, final_estimator__solver=saga, stack_method=predict_proba; total time= 1.5min\n",
      "[CV] END final_estimator__C=0.2, final_estimator__penalty=l2, final_estimator__solver=saga, stack_method=predict_proba; total time= 1.5min\n",
      "[CV] END final_estimator__C=0.9, final_estimator__penalty=l2, final_estimator__solver=liblinear, stack_method=auto; total time= 1.5min\n",
      "[CV] END final_estimator__C=0.2, final_estimator__penalty=l2, final_estimator__solver=saga, stack_method=predict_proba; total time= 1.6min\n",
      "[CV] END final_estimator__C=0.9, final_estimator__penalty=l2, final_estimator__solver=liblinear, stack_method=auto; total time= 1.6min\n",
      "[CV] END final_estimator__C=0.9, final_estimator__penalty=l2, final_estimator__solver=liblinear, stack_method=auto; total time= 1.6min\n",
      "[CV] END final_estimator__C=0.9, final_estimator__penalty=l2, final_estimator__solver=liblinear, stack_method=auto; total time= 1.6min\n",
      "[CV] END final_estimator__C=0.9, final_estimator__penalty=l2, final_estimator__solver=liblinear, stack_method=auto; total time= 1.5min\n",
      "[CV] END final_estimator__C=0.8, final_estimator__penalty=l2, final_estimator__solver=saga, stack_method=predict_proba; total time= 1.5min\n",
      "[CV] END final_estimator__C=0.8, final_estimator__penalty=l2, final_estimator__solver=saga, stack_method=predict_proba; total time= 1.5min\n",
      "[CV] END final_estimator__C=0.8, final_estimator__penalty=l2, final_estimator__solver=saga, stack_method=predict_proba; total time= 1.6min\n",
      "[CV] END final_estimator__C=0.8, final_estimator__penalty=l2, final_estimator__solver=saga, stack_method=predict_proba; total time= 1.6min\n",
      "[CV] END final_estimator__C=0.8, final_estimator__penalty=l2, final_estimator__solver=saga, stack_method=predict_proba; total time= 1.5min\n",
      "[CV] END final_estimator__C=0.4, final_estimator__penalty=l2, final_estimator__solver=liblinear, stack_method=predict_proba; total time= 1.5min\n",
      "[CV] END final_estimator__C=0.4, final_estimator__penalty=l2, final_estimator__solver=liblinear, stack_method=predict_proba; total time= 1.6min\n",
      "[CV] END final_estimator__C=0.4, final_estimator__penalty=l2, final_estimator__solver=liblinear, stack_method=predict_proba; total time= 1.6min\n",
      "[CV] END final_estimator__C=0.4, final_estimator__penalty=l2, final_estimator__solver=liblinear, stack_method=predict_proba; total time=  55.8s\n",
      "[CV] END final_estimator__C=0.4, final_estimator__penalty=l2, final_estimator__solver=liblinear, stack_method=predict_proba; total time=  48.2s\n",
      "{'stack_method': 'auto', 'final_estimator__solver': 'liblinear', 'final_estimator__penalty': 'l2', 'final_estimator__C': 0.1}\n",
      "0.8647429425808326\n",
      "0.8651111685625646\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'final_estimator__penalty': ['l1', 'l2'],\n",
    "    'final_estimator__C': np.arange(0.1, 1.1, 0.1),\n",
    "    'final_estimator__solver': ['liblinear', 'saga'],\n",
    "    'stack_method': ['auto', 'predict_proba'],\n",
    "    # random selection of estimators\n",
    "    'estimators': np\n",
    "    ]\n",
    "}\n",
    "\n",
    "stacking_search = RandomizedSearchCV(StackingClassifier(estimators=[('gb', gb_search.best_estimator_), ('forest', forest_search.best_estimator_), ('knn', knn_search.best_estimator_), ('ada', ada_search.best_estimator_)], final_estimator=LogisticRegression()), param_grid, cv=5, scoring='accuracy', return_train_score=True, n_jobs=-1, n_iter=10, verbose=2)\n",
    "stacking_search.fit(X_train, y_train)\n",
    "print(stacking_search.best_params_)\n",
    "print(stacking_search.best_score_)\n",
    "y_pred = stacking_search.predict(X_val)\n",
    "print(accuracy_score(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 12\u001b[0m\n\u001b[1;32m      3\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_layer_sizes\u001b[39m\u001b[38;5;124m'\u001b[39m: [(\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m), (\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m50\u001b[39m), (\u001b[38;5;241m100\u001b[39m,)],\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtanh\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madaptive\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      9\u001b[0m }\n\u001b[1;32m     11\u001b[0m mlp_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(MLPClassifier(), param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, return_train_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mmlp_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(mlp_search\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(mlp_search\u001b[38;5;241m.\u001b[39mbest_score_)\n",
      "File \u001b[0;32m~/Desktop/Coding/kaggle/.conda/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Coding/kaggle/.conda/lib/python3.11/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/Coding/kaggle/.conda/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1809\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1808\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1809\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1810\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1811\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1812\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1813\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Coding/kaggle/.conda/lib/python3.11/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/Coding/kaggle/.conda/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Coding/kaggle/.conda/lib/python3.11/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m~/Desktop/Coding/kaggle/.conda/lib/python3.11/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Coding/kaggle/.conda/lib/python3.11/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50, 50, 50), (50, 100, 50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': np.linspace(0.0001, 0.001, 10),\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "}\n",
    "\n",
    "mlp_search = RandomizedSearchCV(MLPClassifier(), param_grid, cv=5, scoring='accuracy', return_train_score=True, n_jobs=-1, n_iter=10, verbose=2)\n",
    "mlp_search.fit(X_train, y_train)\n",
    "print(mlp_search.best_params_)\n",
    "print(mlp_search.best_score_)\n",
    "y_pred = mlp_search.predict(X_val)\n",
    "print(accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8633337642192348\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier()\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred = mlp.predict(X_val)\n",
    "print(accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8749551154072649\n",
      "0.858906411582213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandonmpark/Desktop/Coding/kaggle/.conda/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(activation='tanh', alpha=0.001, hidden_layer_sizes=(50, 50), learning_rate='adaptive', solver='adam')\n",
    "mlp.fit(X_train, y_train)\n",
    "print(mlp.score(X_train, y_train))\n",
    "y_pred = mlp.predict(X_val)\n",
    "print(accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
